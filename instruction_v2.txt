整体目标：你好，Cursor。我正在基于一个已有的React Native前端界面（如我提供的截图所示）开发一个智能语音家居助手。我需要你协助我完善前端功能，并指导Spring Boot后端与Python NLP服务的集成。

当前前端界面包含：
* 顶部栏：应用标题“家庭助手”，一个设置（齿轮）图标，一个刷新图标。
* 环境信息：显示温度、湿度等。
* 设备列表区域：显示如“客厅灯光”、“卧室灯光”等设备及其状态（如亮度百分比）。
* 底部操作区域：一个醒目的“语音命令”按钮。

我的核心需求是：
1.  **激活并实现“语音命令”按钮功能。**
2.  **在界面上新增文本输入方式来发送命令。**
3.  **实现点击顶部“设置”齿轮图标后导航到新的设置界面。新的界面有返回键能返回原本的显示界面**
4.  **命令处理后，在前端清晰显示STT识别文本、NLU理解结果以及家居设备状态的变更确认。**

Spring Boot后端将调用一个已有的Python `nlp_service` (FastAPI服务，提供`/process_audio`和`/process_text`接口)进行NLP处理，并根据NLU结果在后端更新模拟的家居设备状态。
Python `nlp_service`功能（假设此部分已按先前指导完成或即将完成）：
1.  通过FastAPI提供`/process_audio`和`/process_text`接口。
2.  `process_audio`：执行STT -> NLU -> 可选TTS。
3.  `process_text`：执行NLU -> 可选TTS。
4.  NLU部分暂时使用占位逻辑。
---
**第一部分：React Native前端实现**
---

请基于我们原本的界面搭建风格，为主要的应用屏幕组件添加以下功能的代码实现建议和结构。请使用React Hooks，并选择合适的库（如Expo项目使用 `expo-av`，Bare React Native项目使用 `react-native-audio-recorder-player` 或 `react-native-voice` 等）。”

1.  **UI组件布局：**
    * “建议一个包含以下元素的界面：”
        * 一个“按住说话”按钮 (或 “开始录音”/“停止录音” 按钮组)。
        * 一个 `TextInput` 组件用于文本命令输入。
        * 一个“发送文本”按钮。
        * 一个专门的区域（例如，一个 `View` 包含多个 `Text` 组件，或一个简单的弹窗/模态框）用于显示状态信息、STT文本、NLU解读和设备操作反馈。

2.  **状态管理 (使用 `useState` Hook)：**
    * “定义所需的状态变量，例如：”
        * `const [isRecording, setIsRecording] = useState(false);`
        * `const [isLoading, setIsLoading] = useState(false);`
        * `const [sttText, setSttText] = useState('');`
        * `const [nluResult, setNluResult] = useState(null); // e.g., { action: '', entity: '', location: '' }`
        * `const [deviceFeedback, setDeviceFeedback] = useState('');`
        * `const [errorMessage, setErrorMessage] = useState('');`
        * `const [textInputValue, setTextInputValue] = useState('');`
        * `const [userSettings, setUserSettings] = useState({ ttsEnabled: true }); // 示例用户设置`

3.  **麦克风权限请求：**
    * “展示如何在组件加载时或首次点击录音按钮时请求麦克风权限 (例如，使用 `expo-av` 的 `Audio.requestPermissionsAsync()` 或 `react-native-permissions` 库)。”

4.  **音频录制逻辑：**
    * “请选择一个适合React Native的音频录制库（如果是Expo项目，优先推荐 `expo-av`；如果是Bare React Native，可考虑 `react-native-audio-recorder-player` 或 `react-native-voice`，并说明选择理由和基本用法）。”
    * “提供 `startRecording` 函数：”
        * 设置 `isRecording(true)`。
        * 清除之前的状态（`sttText`, `nluResult`等）。
        * 开始录音。
    * “提供 `stopRecording` 函数：”
        * 停止录音。
        * 设置 `isRecording(false)` 和 `setIsLoading(true)`。
        * 获取录音文件的URI。
        * 调用下述的 `sendAudioCommand` 函数。

5.  **API调用函数 - 发送音频命令：**
    * “提供 `async function sendAudioCommand(audioUri, settings)`：”
        * “创建一个 `FormData` 对象。”
        * “根据 `audioUri` 读取音频文件，并将其（例如，命名为 `audio`）添加到 `FormData` 中。确保正确设置文件名和类型。”
        * “将 `settings` 对象（JSON字符串化后）也作为一个字段（例如，命名为 `settingsJson`）添加到 `FormData` 中。”
        * “使用 `Workspace` API (或 `axios`) 向Spring Boot后端的 `/api/command/audio` 端点发送POST请求。”
        * “处理响应：如果成功，解析JSON，更新 `sttText`, `nluResult`, `deviceFeedback` 等状态；如果失败，更新 `errorMessage` 状态。”
        * “最后设置 `setIsLoading(false)`。”

6.  **API调用函数 - 发送文本命令：**
    * “提供 `async function sendTextCommand(text, settings)`：”
        * “创建一个包含 `textInput: text` 和 `settings: settings` 的JavaScript对象作为请求体。”
        * “使用 `Workspace` API (或 `axios`) 向Spring Boot后端的 `/api/command/text` 端点发送POST请求，请求头 `Content-Type` 设置为 `application/json`。”
        * “处理响应：逻辑与 `sendAudioCommand` 类似，更新相关状态。”
        * “最后设置 `setIsLoading(false)`。”

7.  **结果显示逻辑：**
    * “在JSX中，根据 `isLoading`, `sttText`, `nluResult`, `deviceFeedback`, `errorMessage` 等状态来条件渲染不同的UI元素和文本信息。”

8.  **（可选）TTS音频播放：**
    * “如果Spring Boot后端在响应中返回了 `ttsOutputReferenceFromNlp` (例如一个可播放的URL或Base64数据)，简要说明前端如何使用适当的库（如 `expo-av` 的 `Audio.Sound` 或 `react-native-sound`）来播放这个音频。”

---
**第二部分：Spring Boot后端实现 (回顾与确认)**
---
1.  **模拟家居设备状态管理：**
    * **`Device.java`**: 定义包含`id`, `name`, `type`, `status`, `location`的实体类。
    * **`DeviceRepository.java`**: 使用内存存储 (如 `ConcurrentHashMap`) 管理一组预定义设备。
    * **`DeviceService.java`**: 提供 `updateDeviceState(entityType, location, action)` 方法，根据NLU结果查找并更新设备状态，返回操作结果字符串。

2.  **Python NLP服务客户端 (`NlpServiceClient.java`)：**
    * 使用 `RestTemplate` 或 `WebClient`。
    * 从 `application.properties` 读取 `nlp.service.baseurl`。
    * 实现 `callProcessAudio(MultipartFile audioFile, Map<String, Object> settings)` 方法，向Python服务的 `/process_audio` 发送 `multipart/form-data` 请求。
    * 实现 `callProcessText(String textInput, Map<String, Object> settings)` 方法，向Python服务的 `/process_text` 发送 `application/json` 请求。
    * 定义 `NlpServiceResponseDto.java` DTO类来映射Python服务返回的JSON。

3.  **主业务编排服务 (`SmartHomeCommandOrchestrator.java`)：**
    * 注入 `NlpServiceClient` 和 `DeviceService`。
    * 实现 `FrontendResponseDto orchestrateAudioCommand(MultipartFile audioFile, Map<String, Object> userSettings)` 方法：调用NLP服务 -> 提取NLU -> 调用DeviceService -> 构建并返回`FrontendResponseDto`。
    * 实现 `FrontendResponseDto orchestrateTextCommand(String textInput, Map<String, Object> userSettings)` 方法：逻辑类似。

4.  **Spring MVC Controller (`VoiceCommandController.java`)：**
    * 注入 `SmartHomeCommandOrchestrator`。
    * `/api/command/audio` (POST): 接收 `MultipartFile audioFile` 和 `String settingsJson` (或多个`@RequestParam` for settings)，调用 `orchestrateAudioCommand`。
    * `/api/command/text` (POST): 接收包含 `textInput` 和 `settings` 的JSON请求体 (定义 `TextCommandRequestDto.java`)，调用 `orchestrateTextCommand`。
    * 所有端点返回 `ResponseEntity<FrontendResponseDto>`。

5.  **前端响应DTO (`FrontendResponseDto.java`)：**
    * 定义此类以统一返回给React Native前端的JSON结构。包含字段：
        * `String sttText` (STT识别的文本，语音输入时填充)
        * `NluResultDisplayDto nluResult` (简化的NLU结果对象，如包含 `action`, `entity`, `location`)
        * `String deviceActionFeedback` (设备操作的结果消息，例如：“客厅灯已成功开启。”)
        * `boolean commandSuccess` (整个命令是否成功)
        * `String errorMessage` (错误信息)
        * `String ttsOutputReferenceFromNlp` (可选，来自NLP服务的TTS参考)
    * `NluResultDisplayDto.java`: 包含 `action`, `entity`, `location` 等前端展示所需字段。


---
**第三部分：Python `nlp_service` (回顾与确认)**
---

请确认Python `nlp_service` 已按先前指导完成，能够处理音频和文本输入，执行STT、NLU（占位）、可选TTS，并通过FastAPI接口返回包含 `transcribedText`, `nluResult`, `ttsOutputReference` 等信息的JSON。”

---
**总结性提示给Cursor：**
---
* “请为React Native的 `HomeScreen.js` (或类似主屏幕组件) 提供一个相对完整的、包含上述功能的代码骨架。重点在于状态管理、函数定义、API调用和条件渲染部分。”
* “对于React Native中的库选择（如录音、导航、音频播放），如果存在多种流行选项，请说明你的选择并简述理由，或者提供Expo和Bare React Native两种方案的建议。”
* “请在所有代码层面（React Native, Java, Python）都考虑清晰的错误处理和用户反馈机制。”
* “React Native代码请使用 `async/await` 处理异步操作，并遵循良好的React Hooks使用规范。”

---